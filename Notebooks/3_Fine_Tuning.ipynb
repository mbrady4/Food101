{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning the image classifier\n",
    "\n",
    "In the prior notebook, we trained a custom top layer on the food-101 training set as a first step in our tranfer learning process. In this notebook, we will make part of the convolutional base trainable in addition to the top layer. This will allow our model to learn the nuances of the food-101 dataset more comprehensively. Overfitting is a major concern at this stage, thus we will hold back 10% of the train dataset to serve as a validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a preprocessing pipeline\n",
    "\n",
    "Our preprocessing pipeline will be identical to our prior notebook; however, we will hold back a greater portion of the data for a validation set as overfitting is a major concern when fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 68175 images belonging to 102 classes.\n",
      "Found 7575 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "# create the image data generator object\n",
    "datagen = ImageDataGenerator(rescale=1./255, \n",
    "                             brightness_range=[0.8,1.2],\n",
    "                             rotation_range=20,\n",
    "                             zoom_range=[0.8,1.2],\n",
    "                             fill_mode='nearest',\n",
    "                             validation_split=0.1)\n",
    "\n",
    "# prints \"XXX images belonging to 102 classes\"\n",
    "train_datagen = datagen.flow_from_directory('data/train/', seed=42, class_mode='categorical', subset='training', target_size=(512,512))\n",
    "# prints \"XXX images belonging to 102 classes\"\n",
    "val_datagen = datagen.flow_from_directory('data/train/', seed=42, class_mode='categorical', subset='validation', target_size=(512,512)) \n",
    "\n",
    "# the number of steps per epoch will be an important parameter to specify during model training\n",
    "train_steps = len(train_datagen) #1894\n",
    "val_steps = len(val_datagen) #474\n",
    "\n",
    "# the number of nodes in our output layer must match the number of classes in our dataset\n",
    "classes = len(list(train_datagen.class_indices.keys())) #102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the model saved as the output of the prior notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "model = load_model('trained_top_resnet.h5', compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, as seen in the model summary below, the image data generators are detecting 102 classes instead of the 101 classes that they should be. This appears to be a hidden empty folder or bug. We will account for this when we evaluate performance in a future notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Model)           (None, 2048)              23564800  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 102)               52326     \n",
      "=================================================================\n",
      "Total params: 24,676,454\n",
      "Trainable params: 24,625,894\n",
      "Non-trainable params: 50,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the names of every layer in our model\n",
    "# Not shown for readability purposes\n",
    "# for layer in model.get_layer('resnet50v2').layers:\n",
    "    # print(layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, our model has a large number of trainable layers. We want to reduce this to only have the top connected layers and the top part of the convolutional base be trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable = False\n",
    "for layer in model.get_layer('resnet50v2').layers:\n",
    "        if layer.name == 'conv5_block1_preact_bn':\n",
    "            set_trainable = True\n",
    "        if set_trainable == True:\n",
    "            layer.trainable = True\n",
    "        else:\n",
    "            layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen below, the trainable layers have been reduced substantially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compile the model similiar to before; however, we will now specify a smaller learning rate. We do this to avoid our model making large adjustments to the convolutional base at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=RMSprop(lr=0.0001),\n",
    "                      metrics=['acc','top_k_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same callbacks as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='tuned_resnet.h5',\n",
    "        monitor='val_acc',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=2,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen below, our models performance on the validation set peaks at epoch 9. At this stage our train accuracy is signficantly outperforming our validation accuracy (86.2% versus 76.9%). This is cause for concern and something to closely monitor moving forward. \n",
    "\n",
    "Overall, this performance is far superior to the performance in our prior notebook which peaked at 44.7% validation accuracy. This shows the power of fine tuning our model. In the next notebook, we will conduct further fine tuning by including the entire train dataset in our training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 8951s - loss: 1.7749 - acc: 0.5652 - top_k_categorical_accuracy: 0.8100 - val_loss: 1.1696 - val_acc: 0.7071 - val_top_k_categorical_accuracy: 0.9011\n",
      "Epoch 2/50\n",
      " - 6123s - loss: 1.3890 - acc: 0.6586 - top_k_categorical_accuracy: 0.8708 - val_loss: 1.2801 - val_acc: 0.7296 - val_top_k_categorical_accuracy: 0.9166\n",
      "Epoch 3/50\n",
      " - 5885s - loss: 1.1733 - acc: 0.7130 - top_k_categorical_accuracy: 0.9004 - val_loss: 1.0770 - val_acc: 0.7473 - val_top_k_categorical_accuracy: 0.9213\n",
      "Epoch 4/50\n",
      " - 5875s - loss: 1.0215 - acc: 0.7502 - top_k_categorical_accuracy: 0.9195 - val_loss: 0.8403 - val_acc: 0.7500 - val_top_k_categorical_accuracy: 0.9233\n",
      "Epoch 5/50\n",
      " - 5827s - loss: 0.9060 - acc: 0.7783 - top_k_categorical_accuracy: 0.9313 - val_loss: 0.9589 - val_acc: 0.7633 - val_top_k_categorical_accuracy: 0.9211\n",
      "Epoch 6/50\n",
      " - 5764s - loss: 0.7917 - acc: 0.8049 - top_k_categorical_accuracy: 0.9448 - val_loss: 0.8857 - val_acc: 0.7584 - val_top_k_categorical_accuracy: 0.9251\n",
      "Epoch 7/50\n",
      " - 5742s - loss: 0.7070 - acc: 0.8273 - top_k_categorical_accuracy: 0.9539 - val_loss: 1.2360 - val_acc: 0.7646 - val_top_k_categorical_accuracy: 0.9267\n",
      "Epoch 8/50\n",
      " - 5749s - loss: 0.6282 - acc: 0.8454 - top_k_categorical_accuracy: 0.9616 - val_loss: 0.6133 - val_acc: 0.7654 - val_top_k_categorical_accuracy: 0.9233\n",
      "Epoch 9/50\n",
      " - 5760s - loss: 0.5603 - acc: 0.8620 - top_k_categorical_accuracy: 0.9683 - val_loss: 0.4989 - val_acc: 0.7687 - val_top_k_categorical_accuracy: 0.9250\n",
      "Epoch 10/50\n",
      " - 5773s - loss: 0.5090 - acc: 0.8753 - top_k_categorical_accuracy: 0.9725 - val_loss: 0.6716 - val_acc: 0.7658 - val_top_k_categorical_accuracy: 0.9234\n",
      "Epoch 11/50\n",
      " - 5499s - loss: 0.4519 - acc: 0.8888 - top_k_categorical_accuracy: 0.9771 - val_loss: 1.7424 - val_acc: 0.7570 - val_top_k_categorical_accuracy: 0.9205\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_datagen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=50,\n",
    "    verbose=2,\n",
    "    validation_data=val_datagen,\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
