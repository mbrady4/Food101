{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Fine Tuning\n",
    "\n",
    "In the prior notebook, we fine tuned our model by making the top part of the convolutional base trainable. During our prior training we held 10% of the data back as a validation set to help avoid overfitting. In this notebook, we will repeat the same process by further fine tuning the model, but will only hold back 1% of the train data for validation. We must be very mindful of overfitting at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a preprocessing pipeline\n",
    "\n",
    "Our preprocessing pipeline will be identical to our prior notebook; however, we will hold back a very small portion of the data for a validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75043 images belonging to 102 classes.\n",
      "Found 707 images belonging to 102 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255, \n",
    "                             brightness_range=[0.7,1.3],\n",
    "                             rotation_range=30,\n",
    "                             zoom_range=[0.7,1.3],\n",
    "                             fill_mode='nearest',\n",
    "                             validation_split=0.01)\n",
    "\n",
    "# prints \"XXX images belonging to 102 classes\"\n",
    "train_datagen = datagen.flow_from_directory('data/train/', seed=42, class_mode='categorical', subset='training', target_size=(512,512))\n",
    "# prints \"XXX images belonging to 102 classes\"\n",
    "val_datagen = datagen.flow_from_directory('data/train/', seed=42, class_mode='categorical', subset='validation', target_size=(512,512)) \n",
    "\n",
    "train_steps = len(train_datagen) #1894\n",
    "val_steps = len(val_datagen) #474\n",
    "classes = len(list(train_datagen.class_indices.keys())) #102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the model saved as the output of the prior notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('tuned_resnet.h5', compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, as seen in the model summary below, the image data generators are detecting 102 classes instead of the 101 classes that they should be. This appears to be a hidden empty folder or bug. We will account for this when we evaluate performance in a future notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50v2 (Model)           (None, 2048)              23564800  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 102)               52326     \n",
      "=================================================================\n",
      "Total params: 24,676,454\n",
      "Trainable params: 16,077,414\n",
      "Non-trainable params: 8,599,040\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the names of every layer in our model\n",
    "# Not shown for readability purposes\n",
    "# for layer in model.get_layer('resnet50v2').layers:\n",
    "    # print(layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown below, our model's trainable weights were appropriately adjusted in the prior notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will compile the model similiar to before; however, we will now specify an even smaller learning rate. We do this to avoid our model making large adjustments to the convolutional base at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=RMSprop(lr=0.00005),\n",
    "                      metrics=['acc','top_k_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same callbacks as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath='fully_trained_resnet.h5',\n",
    "        monitor='acc',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_acc',\n",
    "        patience=2,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen below, we get a minor performance bump by training on 99% of the train data versus 90% in the prior notebook (78.7% vs. 76.9%). We also very quickly begin to overfit the datasets. It should also be noted, that we are now using a much small validation set which introduces some randomness into performance across epochs. \n",
    "\n",
    "In the next notebook, we will evaluate our model's performance on the test dataset and explore our ability to boost performance with test time augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 6469s - loss: 0.6032 - acc: 0.8556 - top_k_categorical_accuracy: 0.9618 - val_loss: 0.5635 - val_acc: 0.7638 - val_top_k_categorical_accuracy: 0.9335\n",
      "Epoch 2/15\n",
      " - 6297s - loss: 0.5430 - acc: 0.8686 - top_k_categorical_accuracy: 0.9683 - val_loss: 0.0549 - val_acc: 0.7779 - val_top_k_categorical_accuracy: 0.9321\n",
      "Epoch 3/15\n",
      " - 6371s - loss: 0.5002 - acc: 0.8792 - top_k_categorical_accuracy: 0.9721 - val_loss: 0.0263 - val_acc: 0.7864 - val_top_k_categorical_accuracy: 0.9307\n",
      "Epoch 4/15\n",
      " - 6145s - loss: 0.4642 - acc: 0.8882 - top_k_categorical_accuracy: 0.9752 - val_loss: 1.6273 - val_acc: 0.7610 - val_top_k_categorical_accuracy: 0.9264\n",
      "Epoch 5/15\n",
      " - 5909s - loss: 0.4313 - acc: 0.8960 - top_k_categorical_accuracy: 0.9781 - val_loss: 0.1141 - val_acc: 0.7511 - val_top_k_categorical_accuracy: 0.9307\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    train_datagen,\n",
    "    steps_per_epoch=train_steps,\n",
    "    epochs=15,\n",
    "    verbose=2,\n",
    "    validation_data=val_datagen,\n",
    "    validation_steps=val_steps,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
